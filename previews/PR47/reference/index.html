<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · KnetNLPModels.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="KnetNLPModels.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">KnetNLPModels.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li class="is-active"><a class="tocitem" href>Reference</a><ul class="internal"><li><a class="tocitem" href="#Contents"><span>Contents</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/master/docs/src/reference.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h1><p>​</p><h2 id="Contents"><a class="docs-heading-anchor" href="#Contents">Contents</a><a id="Contents-1"></a><a class="docs-heading-anchor-permalink" href="#Contents" title="Permalink"></a></h2><p>​</p><ul><li><a href="#Reference">Reference</a></li><ul><li><a href="#Contents">Contents</a></li><li><a href="#Index">Index</a></li></ul></ul><p>​</p><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><p>​</p><ul><li><a href="#KnetNLPModels.KnetNLPModel-Tuple{T} where T&lt;:Chain"><code>KnetNLPModels.KnetNLPModel</code></a></li><li><a href="#KnetNLPModels.KnetNLPModel"><code>KnetNLPModels.KnetNLPModel</code></a></li><li><a href="#KnetNLPModels.accuracy-Tuple{AbstractKnetNLPModel}"><code>KnetNLPModels.accuracy</code></a></li><li><a href="#KnetNLPModels.build_layer_from_vec!-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractVector{T}, Int64}} where {T&lt;:Number, N}"><code>KnetNLPModels.build_layer_from_vec!</code></a></li><li><a href="#KnetNLPModels.build_nested_array_from_vec-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}}} where {T&lt;:Number, S}"><code>KnetNLPModels.build_nested_array_from_vec</code></a></li><li><a href="#KnetNLPModels.build_nested_array_from_vec!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}}} where {T, S}"><code>KnetNLPModels.build_nested_array_from_vec!</code></a></li><li><a href="#KnetNLPModels.create_minibatch-Tuple{Any, Any, Any}"><code>KnetNLPModels.create_minibatch</code></a></li><li><a href="#KnetNLPModels.flag_dim-Tuple{Any}"><code>KnetNLPModels.flag_dim</code></a></li><li><a href="#KnetNLPModels.reset_minibatch_test!-Tuple{AbstractKnetNLPModel}"><code>KnetNLPModels.reset_minibatch_test!</code></a></li><li><a href="#KnetNLPModels.reset_minibatch_train!-Tuple{AbstractKnetNLPModel}"><code>KnetNLPModels.reset_minibatch_train!</code></a></li><li><a href="#KnetNLPModels.set_size_minibatch!-Tuple{AbstractKnetNLPModel, Int64}"><code>KnetNLPModels.set_size_minibatch!</code></a></li><li><a href="#KnetNLPModels.set_vars!-Union{Tuple{T}, Tuple{AbstractVector{AutoGrad.Param}, AbstractVector{&lt;:AbstractArray{T}}}} where T&lt;:Number"><code>KnetNLPModels.set_vars!</code></a></li><li><a href="#KnetNLPModels.vcat_arrays_vector-Tuple{AbstractVector{AutoGrad.Param}}"><code>KnetNLPModels.vcat_arrays_vector</code></a></li><li><a href="#KnetNLPModels.vector_params-Tuple{C} where C&lt;:Chain"><code>KnetNLPModels.vector_params</code></a></li><li><a href="#NLPModels.grad!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}, AbstractVector{T}}} where {T, S}"><code>NLPModels.grad!</code></a></li><li><a href="#NLPModels.obj-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}}} where {T, S}"><code>NLPModels.obj</code></a></li></ul><p>​</p><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.KnetNLPModel" href="#KnetNLPModels.KnetNLPModel"><code>KnetNLPModels.KnetNLPModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KnetNLPModel{T, S, C &lt;: Chain} &lt;: AbstractNLPModel{T, S}</code></pre><p>Data structure that makes the interfaces between neural networks defined with <a href="https://github.com/denizyuret/Knet.jl">Knet.jl</a> and <a href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl">NLPModels</a>. A KnetNLPModel has fields</p><ul><li><code>meta</code> and <code>counters</code> retain informations about the <code>KnetNLPModel</code>;</li><li><code>chain</code> is the chained structure representing the neural network;</li><li><code>data_train</code> is the complete data training set;</li><li><code>data_test</code> is the complete data test;</li><li><code>size_minibatch</code> parametrizes the size of an training and test minibatches, which are of size <code>1/size_minibatch * length(ytrn)</code> and <code>1/size_minibatch * length(ytst)</code>;</li><li><code>training_minibatch_iterator</code> is an iterator over an training minibatches;</li><li><code>test_minibatch_iterator</code> is an iterator over the test minibatches;</li><li><code>current_training_minibatch</code> is the training minibatch used to evaluate the neural network;</li><li><code>current_minibatch_test</code> is the current test minibatch, it is not used in practice;</li><li><code>w</code> is the vector of weights/variables;</li><li><code>layers_g</code> is a nested array used for internal purposes;</li><li><code>nested_array</code> is a vector of <code>Array{T,N}</code>; its shape matches that of <code>chain</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/KnetNLPModels.jl#L15-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.KnetNLPModel-Tuple{T} where T&lt;:Chain" href="#KnetNLPModels.KnetNLPModel-Tuple{T} where T&lt;:Chain"><code>KnetNLPModels.KnetNLPModel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">KnetNLPModel(chain_ANN; size_minibatch=100, data_train=MLDatasets.MNIST.traindata(Float32), data_test=MLDatasets.MNIST.testdata(Float32))</code></pre><p>Build a <code>KnetNLPModel</code> from the neural network represented by <code>chain_ANN</code>. <code>chain_ANN</code> is built using <a href="https://github.com/denizyuret/Knet.jl">Knet.jl</a>, see the <a href="https://JuliaSmoothOptimizers.github.io/KnetNLPModels.jl/dev/tutorial/">tutorial</a> for more details. The other data required are: an iterator over the training dataset <code>data_train</code>, an iterator over the test dataset <code>data_test</code> and the size of the minibatch <code>size_minibatch</code>. Suppose <code>(xtrn,ytrn) = knetnlp.data_train</code>, then the size of each training minibatch will be <code>1/size_minibatch * length(ytrn)</code>. By default, the other data are respectively set to the training dataset and test dataset of <code>MLDatasets.MNIST</code>, with each minibatch a hundredth of the dataset.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/KnetNLPModels.jl#L50-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.accuracy-Tuple{AbstractKnetNLPModel}" href="#KnetNLPModels.accuracy-Tuple{AbstractKnetNLPModel}"><code>KnetNLPModels.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">accuracy(nlp::AbstractKnetNLPModel)</code></pre><p>Compute the accuracy of the network <code>nlp.chain</code> on the entire test dataset.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L56-L60">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.build_layer_from_vec!-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractVector{T}, Int64}} where {T&lt;:Number, N}" href="#KnetNLPModels.build_layer_from_vec!-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractVector{T}, Int64}} where {T&lt;:Number, N}"><code>KnetNLPModels.build_layer_from_vec!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">build_layer_from_vec!(array :: AbstractArray{T, N}, v :: AbstractVector{T}, index :: Int) where {T &lt;: Number, N}</code></pre><p>Inverse of the function <code>Knet.cat1d</code>; set <code>array</code> to the values of <code>v</code> in the range <code>index+1:index+consumed_index</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L63-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.build_nested_array_from_vec!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}}} where {T, S}" href="#KnetNLPModels.build_nested_array_from_vec!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}}} where {T, S}"><code>KnetNLPModels.build_nested_array_from_vec!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">build_nested_array_from_vec!(model::AbstractKnetNLPModel{T,S}, new_w::AbstractVector{T}) where {T, S}
build_nested_array_from_vec!(nested_array :: AbstractVector{&lt;:AbstractArray{T,N} where {N}}, new_w :: AbstractVector{T}) where {T &lt;: Number}</code></pre><p>Build a vector of <code>AbstractArray</code> from <code>new_w</code> similar to <code>Knet.params(model.chain)</code> or <code>nested_array</code>. Call iteratively <code>build_layer_from_vec!</code> to build each intermediate <code>AbstractArray</code>. This method is not optimized; it allocates memory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L118-L125">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.build_nested_array_from_vec-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}}} where {T&lt;:Number, S}" href="#KnetNLPModels.build_nested_array_from_vec-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}}} where {T&lt;:Number, S}"><code>KnetNLPModels.build_nested_array_from_vec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">nested_array = build_nested_array_from_vec(model::AbstractKnetNLPModel{T, S}, v::AbstractVector{T}) where {T &lt;: Number, S}
nested_array = build_nested_array_from_vec(chain_ANN::C, v::AbstractVector{T}) where {C &lt;: Chain, T &lt;: Number}
nested_array = build_nested_array_from_vec(nested_array::AbstractVector{&lt;:AbstractArray{T,N} where {N}}, v::AbstractVector{T}) where {T &lt;: Number}</code></pre><p>Build a vector of <code>AbstractArray</code> from <code>v</code> similar to <code>Knet.params(model.chain)</code>, <code>Knet.params(chain_ANN)</code> or <code>nested_array</code>. Call iteratively <code>build_layer_from_vec</code> to build each intermediate <code>AbstractArray</code>. This method is not optimized; it allocates memory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L80-L88">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.create_minibatch-Tuple{Any, Any, Any}" href="#KnetNLPModels.create_minibatch-Tuple{Any, Any, Any}"><code>KnetNLPModels.create_minibatch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">create_minibatch(X, Y, minibatch_size)</code></pre><p>Create a minibatch&#39;s iterator of the data <code>X</code>, <code>Y</code> of size <code>1/minibatch_size * length(Y)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L9-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.flag_dim-Tuple{Any}" href="#KnetNLPModels.flag_dim-Tuple{Any}"><code>KnetNLPModels.flag_dim</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">flag_dim(x)</code></pre><p>Returns true if x has 3 dimensions. This function is used to reshape X in <code>create_minibatch(X, Y, minibatch_size)</code> in case x has only 3 dimensions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.reset_minibatch_test!-Tuple{AbstractKnetNLPModel}" href="#KnetNLPModels.reset_minibatch_test!-Tuple{AbstractKnetNLPModel}"><code>KnetNLPModels.reset_minibatch_test!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reset_minibatch_test!(nlp::AbstractKnetNLPModel)</code></pre><p>Select a new test minibatch for <code>nlp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L48-L52">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.reset_minibatch_train!-Tuple{AbstractKnetNLPModel}" href="#KnetNLPModels.reset_minibatch_train!-Tuple{AbstractKnetNLPModel}"><code>KnetNLPModels.reset_minibatch_train!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reset_minibatch_train!(nlp::AbstractKnetNLPModel)</code></pre><p>Select a new training minibatch for <code>nlp</code>. Typically used before a new evaluation of the loss function/gradient.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L39-L44">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.set_size_minibatch!-Tuple{AbstractKnetNLPModel, Int64}" href="#KnetNLPModels.set_size_minibatch!-Tuple{AbstractKnetNLPModel, Int64}"><code>KnetNLPModels.set_size_minibatch!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">set_size_minibatch!(knetnlp::AbstractKnetNLPModel, size_minibatch::Int)</code></pre><p>Change the size of both training and test minibatches of the <code>knetnlp</code>. Suppose <code>(xtrn,ytrn) = knetnlp.data_train</code>, then the size of each training minibatch will be <code>1/size_minibatch * length(ytrn)</code>; the test minibatch follows the same logic. After a call of <code>set_size_minibatch!</code>, you must call <code>reset_minibatch_train!(knetnlp)</code> to use a minibatch of the expected size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/KnetNLPModels.jl#L106-L112">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.set_vars!-Union{Tuple{T}, Tuple{AbstractVector{AutoGrad.Param}, AbstractVector{&lt;:AbstractArray{T}}}} where T&lt;:Number" href="#KnetNLPModels.set_vars!-Union{Tuple{T}, Tuple{AbstractVector{AutoGrad.Param}, AbstractVector{&lt;:AbstractArray{T}}}} where T&lt;:Number"><code>KnetNLPModels.set_vars!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">set_vars!(model::AbstractKnetNLPModel{T,S}, new_w::AbstractVector{T}) where {T&lt;:Number, S}
set_vars!(chain_ANN :: C, nested_w :: AbstractVector{&lt;:AbstractArray{T,N} where {N}}) where {C &lt;: Chain, T &lt;: Number}
set_vars!(vars :: Vector{Param}, nested_w :: AbstractVector{&lt;:AbstractArray{T,N} where {N}})</code></pre><p>)</p><p>Set the variables of <code>model</code> (resp. <code>chain_ANN</code> and <code>vars</code>) to <code>new_w</code> (resp. <code>nested_w</code>). Build <code>nested_w</code>: a vector of <code>AbstractArray</code> from <code>new_v</code> similar to <code>Knet.params(model.chain)</code>. Then, set the variables <code>vars</code> of the neural netword <code>model</code> (resp. <code>chain_ANN</code>) to <code>new_w</code> (resp. <code>nested_w</code>). <code>set_vars!(model, new_w)</code> allocates memory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L143-L153">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.vcat_arrays_vector-Tuple{AbstractVector{AutoGrad.Param}}" href="#KnetNLPModels.vcat_arrays_vector-Tuple{AbstractVector{AutoGrad.Param}}"><code>KnetNLPModels.vcat_arrays_vector</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">vcat_arrays_vector(arrays_vector::AbstractVector{Param})</code></pre><p>Flatten a vector of arrays <code>arrays_vector</code> to a vector. It concatenates the vectors produced by the application of <code>Knet.cat1d</code> to each array.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L31-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KnetNLPModels.vector_params-Tuple{C} where C&lt;:Chain" href="#KnetNLPModels.vector_params-Tuple{C} where C&lt;:Chain"><code>KnetNLPModels.vector_params</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">vector_params(chain :: C) where C &lt;: Chain
vector_params(nlp :: AbstractKnetNLPModel)</code></pre><p>Retrieve the variables within <code>chain</code> or <code>nlp.chain</code> as a vector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/utils.jl#L22-L27">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.grad!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}, AbstractVector{T}}} where {T, S}" href="#NLPModels.grad!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}, AbstractVector{T}}} where {T, S}"><code>NLPModels.grad!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">g = grad!(nlp, x, g)</code></pre><p>Evaluate <code>∇f(x)</code>, the gradient of the objective function at <code>x</code> in place.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/KnetNLPModels_methods.jl#L13-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.obj-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}}} where {T, S}" href="#NLPModels.obj-Union{Tuple{S}, Tuple{T}, Tuple{AbstractKnetNLPModel{T, S}, AbstractVector{T}}} where {T, S}"><code>NLPModels.obj</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">f = obj(nlp, x)</code></pre><p>Evaluate <code>f(x)</code>, the objective function of <code>nlp</code> at <code>x</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/KnetNLPModels.jl/blob/58fde21b3a9580d9044711258b0a365532803c7a/src/KnetNLPModels_methods.jl#L1-L5">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorial/">« Tutorial</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 29 July 2022 13:06">Friday 29 July 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
