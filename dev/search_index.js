var documenterSearchIndex = {"docs":
[{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Contents","page":"Reference","title":"Contents","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [KnetNLPModels]","category":"page"},{"location":"reference/#KnetNLPModels.KnetNLPModel","page":"Reference","title":"KnetNLPModels.KnetNLPModel","text":"KnetNLPModel\n\nData structure that interfaces neural networks defined with Knet.jl as an NLPModel.\n\n\n\n\n\n","category":"type"},{"location":"reference/#KnetNLPModels.accuracy-Union{Tuple{KnetNLPModel{T, S, C}}, Tuple{C}, Tuple{S}, Tuple{T}} where {T, S, C}","page":"Reference","title":"KnetNLPModels.accuracy","text":"accuracy(nlp)\n\nComputes the accuracy of the network nlp.chain given the data in nlp.minibatch_test.\n\n\n\n\n\n","category":"method"},{"location":"reference/#KnetNLPModels.build_array-Union{Tuple{T}, Tuple{N}, Tuple{Vector{T}, Knet.KnetArrays.KnetArray{T, N}, Int64}} where {N, T<:Number}","page":"Reference","title":"KnetNLPModels.build_array","text":"build_array(vec, var_layer, index)\n\nInverse of the function Knet.cat1d, it generates a KnetArray similar to varlayer from the vector vec. The values are those of the vector in the range of index to index+consumedindex. This method is not optimised, it consumes memory.\n\n\n\n\n\n","category":"method"},{"location":"reference/#KnetNLPModels.build_nested_array_from_vec-Union{Tuple{C}, Tuple{S}, Tuple{T}, Tuple{KnetNLPModel{T, S, C}, Vector{T}}} where {T, S, C}","page":"Reference","title":"KnetNLPModels.build_nested_array_from_vec","text":"build_nested_array_from_vec(model, v)\n\nBuild a vector of KnetArrays from v similar to Knet.params(model.chain). Call build_array iteratively to build each intermediary KnetArrays. This methods is not optimised, it consumes memory.\n\n\n\n\n\n","category":"method"},{"location":"reference/#KnetNLPModels.build_nested_array_from_vec-Union{Tuple{T}, Tuple{Any, Vector{T}}} where T<:Number","page":"Reference","title":"KnetNLPModels.build_nested_array_from_vec","text":"build_nested_array_from_vec(chain, v)\n\nBuilds a vector of KnetArrays of the same shape as chain of value v. It calls iteratively build_array to build each intermediary KnetArrays. This method is not optimised, it consumes memory.\n\n\n\n\n\n","category":"method"},{"location":"reference/#KnetNLPModels.create_minibatch-Tuple{Any, Any, Any}","page":"Reference","title":"KnetNLPModels.create_minibatch","text":"create_minibatch(X, Y, minibatch_size)\n\nCreate a minibatch of the data (X,Y) of size minibatch_size\n\n\n\n\n\n","category":"method"},{"location":"reference/#KnetNLPModels.reset_minibatch_test!-Union{Tuple{KnetNLPModel{T, S, C}}, Tuple{C}, Tuple{S}, Tuple{T}} where {T, S, C}","page":"Reference","title":"KnetNLPModels.reset_minibatch_test!","text":"reset_minibatch_test!(nlp)\n\nTake a new minibatch for the KnetNLPModel. Usually use before a new accuracy test.\n\n\n\n\n\n","category":"method"},{"location":"reference/#KnetNLPModels.reset_minibatch_train!-Union{Tuple{KnetNLPModel{T, S, C}}, Tuple{C}, Tuple{S}, Tuple{T}} where {T, S, C}","page":"Reference","title":"KnetNLPModels.reset_minibatch_train!","text":"reset_minibatch_train!(nlp)\n\nTake a new minibatch for the KnetNLPModel. Usually use before a new evaluation.\n\n\n\n\n\n","category":"method"},{"location":"reference/#KnetNLPModels.set_vars!-Tuple{Any, Vector}","page":"Reference","title":"KnetNLPModels.set_vars!","text":"set_vars!(model, new_w)\n\nset_vars!(chain, new_w)\n\nSet the variables of model or chain to new_w. Build a vector of KnetArrays from v similar to Knet.params(model.chain). Then it sets these variables to the nested array.\n\n\n\n\n\n","category":"method"},{"location":"reference/#KnetNLPModels.vcat_arrays_vector-Tuple{Any}","page":"Reference","title":"KnetNLPModels.vcat_arrays_vector","text":"vcat_arrays_vector(arrays_vector)\n\nFlatten a vector of arrays to a vector. It keeps the order induce by Knet.cat1d to flatten an array.\n\n\n\n\n\n","category":"method"},{"location":"reference/#KnetNLPModels.vector_params-Tuple{Any}","page":"Reference","title":"KnetNLPModels.vector_params","text":"vector_params(model)\n\nRetrieves the variables as a vector from the vector of variable's arrays that composes model.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.grad!-Union{Tuple{C}, Tuple{S}, Tuple{T}, Tuple{KnetNLPModel{T, S, C}, AbstractVector{T}, AbstractVector{T}}} where {T, S, C}","page":"Reference","title":"NLPModels.grad!","text":"g = grad!(nlp, x, g)\n\nEvaluate f(x), the gradient of the objective function at x in place.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.obj-Union{Tuple{C}, Tuple{S}, Tuple{T}, Tuple{KnetNLPModel{T, S, C}, AbstractVector{T}}} where {T, S, C}","page":"Reference","title":"NLPModels.obj","text":"f = obj(nlp, x)\n\nEvaluate f(x), the objective function of nlp at x.\n\n\n\n\n\n","category":"method"},{"location":"#KnetNLPModels.jl","page":"Home","title":"KnetNLPModels.jl","text":"","category":"section"},{"location":"tutorial/#KnetNLPModels.jl-Tutorial","page":"Tutorial","title":"KnetNLPModels.jl Tutorial","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This tutoriel suppose a prior knowledge about julia and Knet.jl. The tutorial about Knet.jl","category":"page"},{"location":"tutorial/#Define-the-layers-of-interest-(using-Knet.jl)","page":"Tutorial","title":"Define the layers of interest (using Knet.jl)","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"  using Knet\n\n  # Define dense layer\n  struct Dense{T}\n    w :: Param{Knet.KnetArrays.KnetMatrix{T}} # parameters of the layers\n    b :: Param{Knet.KnetArrays.KnetVector{T}} # bias of the layer\n    f # activation function\n  end\n  (d::Dense)(x) = d.f.(d.w * mat(x) .+ d.b) # evaluates the layer for a given input x\n  Dense(i :: Int, o :: Int, f=sigm) = Dense(param(o, i), param0(o), f) # define a dense layer whith an input size of i and an output size of o","category":"page"},{"location":"tutorial/#Definition-of-the-chained-structure-that-evaluates-the-network-and-the-loss-function","page":"Tutorial","title":"Definition of the chained structure that evaluates the network and the loss function","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"  using KnetNLPModels\n\n  struct Chainnll <: Chain # KnetNLPModels.Chain\n    layers\n    Chainnll(layers...) = new(layers)\n  end\n  (c::Chainnll)(x) = (for l in c.layers; x = l(x); end; x) # evaluates the network for a given input\n  (c::Chainnll)(x, y) = Knet.nll(c(x),y) # computes the loss function given the input x and the expected result y\n  (c::Chainnll)(d::Knet.Data) = Knet.nll(c; data=d, average=true) # computes the loss function for a minibatch","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The chained structure that defines the neural network must be a subtype of KnetNLPModels.Chain otherwise there will be an error the KnetNLPModel is instantiated. ","category":"page"},{"location":"tutorial/#Load-the-dataset-required-(MNIST-is-this-example)","page":"Tutorial","title":"Load the dataset required (MNIST is this example)","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"  using MLDatasets\n  xtrn, ytrn = MNIST.traindata(Float32) # MNIST's training database of type T\n  ytrn[ytrn.==0] .= 10 # re-arrange the indices\n  xtst, ytst = MNIST.testdata(Float32) # MNIST's testing database of type T\n  ytst[ytst.==0] .= 10 # re-arrange the indices","category":"page"},{"location":"tutorial/#Neural-network-definition-and-KnetNLPModel","page":"Tutorial","title":"Neural network definition and KnetNLPModel","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"  DenseNet = Chainnll(Dense(784,200), Dense(200,50), Dense(50,10)) \n\n  DenseNetNLPModel = KnetNLPModel(DenseNet; size_minibatch=100, data_train=(xtrn,ytrn), data_test=(xtst,ytst)) # define the KnetNLPModel","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Define the neural network from the chained structure defined previously. Then you can define the KnetNLPModel from the neural network. By default the size of the minibatch is 100 and the dataset used is MNIST.","category":"page"},{"location":"tutorial/#Uses-of-a-KnetNLPModel","page":"Tutorial","title":"Uses of a KnetNLPModel","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Get the dimension of the problem:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"DenseNetNLPModel.meta.nvar","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"or ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"length(vector_params(DenseNetNLPModel))","category":"page"},{"location":"tutorial/#Get-the-current-variables-of-the-network:","page":"Tutorial","title":"Get the current variables of the network:","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"w = vector_params(DenseNetNLPModel) :: Vector{T}","category":"page"},{"location":"tutorial/#Evaluate-the-network-and-the-loss-function-(ie-the-objective):","page":"Tutorial","title":"Evaluate the network and the loss function (ie the objective):","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"NLPModels.obj(DenseNetNLPModel, w)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The length of the vector w must be DenseNetNLPModel.meta.nvar","category":"page"},{"location":"tutorial/#Evaluate-the-loss-function-gradient-at-the-point-w-(ie-the-gradient):","page":"Tutorial","title":"Evaluate the loss function gradient at the point w (ie the gradient):","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"NLPModels.grad!(DenseNetNLPModel, w, g)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The result is stored in g :: Vector{T}(of size DenseNetNLPModel.meta.nvar)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The accuracy of the network can be evaluate with:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"accuracy(DenseNetNLPModel)","category":"page"},{"location":"tutorial/#Default-behaviour","page":"Tutorial","title":"Default behaviour","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"By default neither the training or testing minibatch that evaluates the neural network change between evaluations. To change the training/testing minibatch use:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"reset_minibatch_train!(DenseNetNLPModel)\nreset_minibatch_test!(DenseNetNLPModel)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The size of the minibatch will be about the size define previously (may be improved in the future to be dynamic).","category":"page"}]
}
